{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e6134a-7615-494b-9ff2-718f40fa8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b8d411-d37f-40ce-aa0d-aa437cbf2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stemmer and stopwords\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2648234-9a09-4281-accf-b53a4d9701ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1034f401-3c61-4480-85a5-5f3ee711d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_conflate(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        text = f.read().lower()\n",
    "    \n",
    "    # Remove non-alphabetic characters\n",
    "    words = re.findall(r\"\\b[a-z]+\\b\", text)\n",
    "\n",
    "    # Remove stopwords and apply stemming\n",
    "    stemmed_words = [ps.stem(w) for w in words if w not in stop_words]\n",
    "\n",
    "    # Build document representative (unique stems with frequency)\n",
    "    freq = {}\n",
    "    for w in stemmed_words:\n",
    "        freq[w] = freq.get(w, 0) + 1\n",
    "\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17805913-0e9e-4e7f-9572-a85f1bd979f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all documents\n",
    "documents = {}\n",
    "for fname in [\"doc1.txt\", \"doc2.txt\", \"doc3.txt\", \"doc4.txt\"]:\n",
    "    file_path = os.path.join(folder_path, fname)\n",
    "    documents[fname] = preprocess_and_conflate(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32e2fb5d-0882-44c2-a43f-b750f9dfc232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Representative for doc1.txt:\n",
      "{'machin': 1, 'learn': 2, 'subset': 1, 'artifici': 1, 'intellig': 1, 'algorithm': 1, 'build': 1, 'mathemat': 1, 'model': 2, 'base': 1, 'sampl': 1, 'data': 2, 'known': 1, 'train': 1, 'make': 1, 'predict': 1, 'decis': 1, 'without': 1, 'explicitli': 1, 'program': 1}\n",
      "\n",
      "Document Representative for doc2.txt:\n",
      "{'artifici': 1, 'intellig': 3, 'simul': 1, 'human': 1, 'process': 2, 'machin': 1, 'ai': 1, 'applic': 1, 'includ': 1, 'natur': 1, 'languag': 1, 'speech': 1, 'recognit': 1, 'comput': 1, 'vision': 1, 'abil': 1, 'learn': 1, 'reason': 1, 'self': 1, 'correct': 1}\n",
      "\n",
      "Document Representative for doc3.txt:\n",
      "{'data': 1, 'mine': 2, 'process': 1, 'discov': 1, 'pattern': 1, 'larg': 1, 'dataset': 1, 'combin': 1, 'statist': 1, 'artifici': 1, 'intellig': 1, 'databas': 1, 'system': 1, 'use': 1, 'inform': 1, 'help': 1, 'decis': 1, 'make': 1}\n",
      "\n",
      "Document Representative for doc4.txt:\n",
      "{'comput': 1, 'network': 3, 'connect': 1, 'devic': 1, 'enabl': 1, 'commun': 2, 'involv': 1, 'protocol': 1, 'topolog': 1, 'transmiss': 1, 'media': 1, 'internet': 1, 'largest': 1, 'support': 1, 'global': 1}\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for doc, rep in documents.items():\n",
    "    print(f\"\\nDocument Representative for {doc}:\")\n",
    "    print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e07a5604-7b8f-404d-be8b-00edda5b9725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document representatives saved to documents.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save all document representatives into one JSON file\n",
    "with open(\"./output/documents.json\", \"w\") as f:\n",
    "    json.dump(documents, f, indent=4)\n",
    "\n",
    "print(\"Document representatives saved to documents.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38085637-305f-443b-9a08-9311d2f69418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
